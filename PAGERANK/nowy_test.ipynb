{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23883662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Liczba wykrytych klas: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:33<00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 33.6359, 'train_samples_per_second': 94.185, 'train_steps_per_second': 5.887, 'train_loss': 0.11823393118501914, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =====================\n",
    "# 1. Wczytaj ca≈Çy zbi√≥r danych\n",
    "# =====================\n",
    "df_full = pd.read_csv(\"../Adata/yahoo/train_subset.csv\").reset_index(drop=True)\n",
    "texts_full = df_full[\"text\"].tolist()\n",
    "labels_full = df_full[\"label\"].tolist()\n",
    "\n",
    "# Automatyczne wykrycie liczby klas\n",
    "num_classes = len(set(labels_full))\n",
    "print(f\"üìä Liczba wykrytych klas: {num_classes}\")\n",
    "\n",
    "# =====================\n",
    "# 2. Wybierz ma≈Çy podzbi√≥r do fine-tuningu\n",
    "# =====================\n",
    "np.random.seed(42)\n",
    "samples_per_class = []\n",
    "\n",
    "for label in df_full[\"label\"].unique():\n",
    "    class_subset = df_full[df_full[\"label\"] == label]\n",
    "    k = np.random.randint(3, 5)  # losowo 3-4 pr√≥bki na klasƒô\n",
    "    sampled = class_subset.sample(n=min(k, len(class_subset)), random_state=42)\n",
    "    samples_per_class.append(sampled)\n",
    "\n",
    "df_finetune = pd.concat(samples_per_class).reset_index(drop=True)\n",
    "texts_finetune = df_finetune[\"text\"].tolist()\n",
    "labels_finetune = df_finetune[\"label\"].tolist()\n",
    "\n",
    "# =====================\n",
    "# 3. Przygotuj pary do kontrastowego uczenia\n",
    "# =====================\n",
    "examples = []\n",
    "for i in range(len(texts_finetune)):\n",
    "    for j in range(i + 1, len(texts_finetune)):\n",
    "        label_sim = 1.0 if labels_finetune[i] == labels_finetune[j] else 0.0\n",
    "        examples.append(InputExample(texts=[texts_finetune[i], texts_finetune[j]], label=label_sim))\n",
    "\n",
    "# =====================\n",
    "# 4. Fine-tuning SentenceTransformer\n",
    "# =====================\n",
    "base_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "train_dataloader = DataLoader(examples, shuffle=True, batch_size=16)\n",
    "train_loss = losses.OnlineContrastiveLoss(model=base_model)\n",
    "\n",
    "base_model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=6,\n",
    "    warmup_steps=10,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d39696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb36d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd27a8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wybrane indeksy: [303, 236, 661, 765, 811, 960, 220, 335, 815, 953, 774, 347, 24, 484, 613, 770, 951, 333, 418, 594, 874, 82, 266, 385, 439, 491, 669, 708, 763, 813, 954, 8, 532, 816, 38, 106, 134, 342, 464, 508, 675, 710, 741, 123, 308, 331, 540, 641, 692, 339, 351, 460, 487, 966, 968, 20, 64, 67, 96, 112]\n"
     ]
    }
   ],
   "source": [
    "# # Za≈Ç√≥≈ºmy, ≈ºe mamy listƒô tekst√≥w: zbior_textow\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "# from torch.utils.data import DataLoader\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import adjusted_rand_score\n",
    "# from sklearn.preprocessing import normalize\n",
    "# from sklearn.metrics.pairwise import cosine_distances\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# import umap\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "df_full = pd.read_csv(\"../Adata/yahoo/train_subset.csv\").reset_index(drop=True)\n",
    "texts_full = df_full[\"text\"].tolist()\n",
    "labels_full = df_full[\"label\"].tolist()\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = base_model  # u≈ºyj wcze≈õniej wytrenowanego modelu\n",
    "embeddings = model.encode(texts_full)  # uzyskaj embeddingi dla wszystkich tekst√≥w\n",
    "\n",
    "# Zbuduj graf k-najbli≈ºszych sƒÖsiad√≥w (k-NN) na podstawie kosinusowej odleg≈Ço≈õci miƒôdzy embeddingami\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "k = 5  # przyk≈Çadowa liczba sƒÖsiad√≥w\n",
    "nbrs = NearestNeighbors(n_neighbors=k+1, metric='cosine').fit(embeddings)\n",
    "distances, indices = nbrs.kneighbors(embeddings)\n",
    "# indices zawiera dla ka≈ºdego punktu indeksy jego k+1 najbli≈ºszych (pierwszy to on sam)\n",
    "knn_graph = [nbr_idx[1:] for nbr_idx in indices]  # pomijamy pierwszego (samego siebie)\n",
    "\n",
    "# Inicjalizuj liczbƒô \"g≈Ços√≥w\" (vote count) dla ka≈ºdego kandydata na podstawie grafu\n",
    "N = len(embeddings)\n",
    "votes = [0] * N\n",
    "for i in range(N):\n",
    "    for neigh in knn_graph[i]:\n",
    "        votes[neigh] += 1\n",
    "\n",
    "M = 60  # za≈Ç√≥≈ºmy, ≈ºe chcemy wybraƒá 10 przyk≈Çad√≥w\n",
    "selected = []\n",
    "covered = set()  # zbi√≥r pokrytych (wybranych lub zablokowanych) indeks√≥w\n",
    "\n",
    "while len(selected) < M:\n",
    "    # Znajd≈∫ niepokryty indeks z najwy≈ºszƒÖ liczbƒÖ g≈Ços√≥w\n",
    "    cand = None\n",
    "    best_score = -1\n",
    "    for idx, score in enumerate(votes):\n",
    "        if idx in covered:\n",
    "            continue\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            cand = idx\n",
    "    if cand is None:\n",
    "        break  # brak kandydata (wszystko pokryte)\n",
    "    # Dodaj wybrany punkt do wynikowego zbioru\n",
    "    selected.append(cand)\n",
    "    # Oznacz go i jego sƒÖsiad√≥w jako pokrytych (nie bƒôdƒÖ dalej wybierani)\n",
    "    covered.add(cand)\n",
    "    for neigh in knn_graph[cand]:\n",
    "        covered.add(neigh)\n",
    "    # Aktualizuj liczbƒô g≈Ços√≥w dla pozosta≈Çych (opcjonalnie mo≈ºna te≈º recomputowaƒá od zera ignorujƒÖc pokryte)\n",
    "    for neigh in knn_graph[cand]:\n",
    "        # zmniejszamy \"g≈Çosy\" oddane przez lub na rzecz sƒÖsiad√≥w kandydata\n",
    "        for nn in knn_graph[neigh]:\n",
    "            if nn not in covered:\n",
    "                votes[nn] -= 1\n",
    "\n",
    "# 'selected' zawiera indeksy wybranych przyk≈Çad√≥w\n",
    "print(\"Wybrane indeksy:\", selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57b98ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Utw√≥rz nowy dataframe z wybranych przyk≈Çad√≥w\n",
    "selected_df = df_full.iloc[selected].copy()\n",
    "\n",
    "# # Zapisz do pliku CSV\n",
    "# selected_df.to_csv(\"vote_k_selected_examples.csv\", index=False)\n",
    "\n",
    "# print(\"‚úÖ Zapisano wybrane przyk≈Çady do 'vote_k_selected_examples.csv'\")\n",
    "\n",
    "print(len(pd.unique(selected_df['label'])))\n",
    "\n",
    "selected_df.to_csv(\"selected_samples/yahoo/vote_k_new_model.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anote",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
